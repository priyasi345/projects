{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, time\n",
    "import h5py\n",
    "import numpy as npd\n",
    "from keras.preprocessing.image import ImageDataGenerator,load_img,img_to_array\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import callbacks\n",
    "from keras import backend as K\n",
    "\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/rcmalli/keras-vggface.git\n",
      "  Cloning https://github.com/rcmalli/keras-vggface.git to c:\\users\\renato~1.cas\\appdata\\local\\temp\\pip-req-build-4926xtj_\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\renato.castro\\appdata\\local\\continuum\\anaconda3\\envs\\opencvkeras\\lib\\site-packages (from keras-vggface==0.5) (1.16.0)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\renato.castro\\appdata\\local\\continuum\\anaconda3\\envs\\opencvkeras\\lib\\site-packages (from keras-vggface==0.5) (1.1.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\renato.castro\\appdata\\local\\continuum\\anaconda3\\envs\\opencvkeras\\lib\\site-packages (from keras-vggface==0.5) (2.8.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\renato.castro\\appdata\\local\\continuum\\anaconda3\\envs\\opencvkeras\\lib\\site-packages (from keras-vggface==0.5) (5.2.0)\n",
      "Requirement already satisfied: keras in c:\\users\\renato.castro\\appdata\\local\\continuum\\anaconda3\\envs\\opencvkeras\\lib\\site-packages (from keras-vggface==0.5) (2.2.3)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\renato.castro\\appdata\\local\\continuum\\anaconda3\\envs\\opencvkeras\\lib\\site-packages (from keras-vggface==0.5) (1.11.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\renato.castro\\appdata\\local\\continuum\\anaconda3\\envs\\opencvkeras\\lib\\site-packages (from keras-vggface==0.5) (3.13)\n",
      "Collecting keras_applications>=1.0.6 (from keras->keras-vggface==0.5)\n",
      "  Downloading https://files.pythonhosted.org/packages/90/85/64c82949765cfb246bbdaf5aca2d55f400f792655927a017710a78445def/Keras_Applications-1.0.7-py2.py3-none-any.whl (51kB)\n",
      "Collecting keras_preprocessing>=1.0.5 (from keras->keras-vggface==0.5)\n",
      "  Downloading https://files.pythonhosted.org/packages/c0/bf/0315ef6a9fd3fc2346e85b0ff1f5f83ca17073f2c31ac719ab2e4da0d4a3/Keras_Preprocessing-1.0.9-py2.py3-none-any.whl (59kB)\n",
      "Building wheels for collected packages: keras-vggface\n",
      "  Running setup.py bdist_wheel for keras-vggface: started\n",
      "  Running setup.py bdist_wheel for keras-vggface: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\RENATO~1.CAS\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-vlr7mx2w\\wheels\\36\\07\\46\\06c25ce8e9cd396dabe151ea1d8a2bc28dafcb11321c1f3a6d\n",
      "Successfully built keras-vggface\n",
      "Installing collected packages: keras-vggface, keras-applications, keras-preprocessing\n",
      "  Found existing installation: Keras-Applications 1.0.4\n",
      "    Uninstalling Keras-Applications-1.0.4:\n",
      "      Successfully uninstalled Keras-Applications-1.0.4\n",
      "  Found existing installation: Keras-Preprocessing 1.0.2\n",
      "    Uninstalling Keras-Preprocessing-1.0.2:\n",
      "      Successfully uninstalled Keras-Preprocessing-1.0.2\n",
      "Successfully installed keras-applications-1.0.7 keras-preprocessing-1.0.9 keras-vggface-0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "twisted 18.7.0 requires PyHamcrest>=1.9.0, which is not installed.\n",
      "tensorflow 1.10.0 has requirement numpy<=1.14.5,>=1.13.3, but you'll have numpy 1.16.0 which is incompatible.\n",
      "tensorflow 1.10.0 has requirement setuptools<=39.1.0, but you'll have setuptools 40.2.0 which is incompatible.\n",
      "You are using pip version 10.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/rcmalli/keras-vggface.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_vggface in c:\\users\\renato.castro\\appdata\\local\\continuum\\anaconda3\\envs\\opencvkeras\\lib\\site-packages (0.5)\n",
      "Requirement already satisfied: pillow in c:\\users\\renato.castro\\appdata\\local\\continuum\\anaconda3\\envs\\opencvkeras\\lib\\site-packages (from keras_vggface) (5.2.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\renato.castro\\appdata\\local\\continuum\\anaconda3\\envs\\opencvkeras\\lib\\site-packages (from keras_vggface) (1.11.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\renato.castro\\appdata\\local\\continuum\\anaconda3\\envs\\opencvkeras\\lib\\site-packages (from keras_vggface) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\renato.castro\\appdata\\local\\continuum\\anaconda3\\envs\\opencvkeras\\lib\\site-packages (from keras_vggface) (1.16.0)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\renato.castro\\appdata\\local\\continuum\\anaconda3\\envs\\opencvkeras\\lib\\site-packages (from keras_vggface) (1.1.0)\n",
      "Requirement already satisfied: keras in c:\\users\\renato.castro\\appdata\\local\\continuum\\anaconda3\\envs\\opencvkeras\\lib\\site-packages (from keras_vggface) (2.2.3)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\renato.castro\\appdata\\local\\continuum\\anaconda3\\envs\\opencvkeras\\lib\\site-packages (from keras_vggface) (3.13)\n",
      "Requirement already satisfied: keras_applications>=1.0.6 in c:\\users\\renato.castro\\appdata\\local\\continuum\\anaconda3\\envs\\opencvkeras\\lib\\site-packages (from keras->keras_vggface) (1.0.7)\n",
      "Requirement already satisfied: keras_preprocessing>=1.0.5 in c:\\users\\renato.castro\\appdata\\local\\continuum\\anaconda3\\envs\\opencvkeras\\lib\\site-packages (from keras->keras_vggface) (1.0.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "twisted 18.7.0 requires PyHamcrest>=1.9.0, which is not installed.\n",
      "tensorflow 1.10.0 has requirement numpy<=1.14.5,>=1.13.3, but you'll have numpy 1.16.0 which is incompatible.\n",
      "tensorflow 1.10.0 has requirement setuptools<=39.1.0, but you'll have setuptools 40.2.0 which is incompatible.\n",
      "You are using pip version 10.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install keras_vggface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LATINXINAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG-16 ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = keras.applications.vgg16.VGG16(include_top=False, weights='imagenet', input_tensor=None, input_shape=(3,96,96), pooling=None, classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0xc7b44a8>,\n",
       " <keras.layers.convolutional.Conv2D at 0xc7b4c18>,\n",
       " <keras.layers.convolutional.Conv2D at 0xc7b4a58>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0xc7fccc0>,\n",
       " <keras.layers.convolutional.Conv2D at 0xc7fcdd8>,\n",
       " <keras.layers.convolutional.Conv2D at 0xc8202e8>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0xc83cc50>,\n",
       " <keras.layers.convolutional.Conv2D at 0xc83cdd8>,\n",
       " <keras.layers.convolutional.Conv2D at 0xc86fdd8>,\n",
       " <keras.layers.convolutional.Conv2D at 0xc89dbe0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0xc8bba90>,\n",
       " <keras.layers.convolutional.Conv2D at 0xc8bbba8>,\n",
       " <keras.layers.convolutional.Conv2D at 0xc8f34e0>,\n",
       " <keras.layers.convolutional.Conv2D at 0xc929128>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0xc93fa90>,\n",
       " <keras.layers.convolutional.Conv2D at 0xc93ff60>,\n",
       " <keras.layers.convolutional.Conv2D at 0xc978438>,\n",
       " <keras.layers.convolutional.Conv2D at 0xcbbe748>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0xcbe3d68>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3, 96, 96)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 96, 96)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 96, 96)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 48, 48)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 48, 48)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 48, 48)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 128, 24, 24)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 256, 24, 24)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 256, 24, 24)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 256, 24, 24)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 256, 12, 12)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 512, 12, 12)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 512, 12, 12)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 512, 12, 12)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 512, 6, 6)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 512, 6, 6)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 512, 6, 6)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 512, 6, 6)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 512, 3, 3)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine import  Model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=vgg16.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# add the model on top of the convolutional base\n",
    "#custom_vgg_model = Model(vgg16.input,top_model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,180,161\n",
      "Trainable params: 1,180,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "top_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  Sequential()\n",
    "model.add(vgg16)\n",
    "model.add(top_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.training.Model at 0xcbe3fd0>,\n",
       " <keras.engine.sequential.Sequential at 0xd04c1d0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filepath='weights/latinxinai1_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=96x96 at 0xE4155C0>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height = (96,96)\n",
    "img = load_img('real_test_4113.jpg',target_size=(96,96))\n",
    "print(img)\n",
    "imgArray = img_to_array(img)\n",
    "print(type(imgArray))\n",
    "imgArray = imgArray.reshape(1,3,img_width, img_height)\n",
    "imgArray = imgArray/float(255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "outLabel = int(model.predict_classes(imgArray,verbose=0))\n",
    "print(outLabel)\n",
    "# Real: 1    |  Fake: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "if __name__ == \"__main__\":\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    img_width = 96\n",
    "    img_height = 96\n",
    "    \n",
    "    cascPath = \"haarcascade_frontalface_alt.xml\"\n",
    "    faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "\n",
    "    sample_number = 1\n",
    "    count = 0\n",
    "    measures = np.zeros(sample_number, dtype=np.float)\n",
    "\n",
    "    while True:\n",
    "        ret, img_bgr = cap.read()\n",
    "        if ret is False:\n",
    "            print(\"Error not camera found. Please turn it on.\")\n",
    "            break\n",
    "\n",
    "        img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        faces = faceCascade.detectMultiScale(img_gray, scaleFactor = 1.05, minNeighbors = 5) \n",
    "\n",
    "        frame = cv2.resize(img_bgr,(96,96))\n",
    "        for i, (x, y, w, h) in enumerate(faces):\n",
    "\n",
    "            imgArray = frame.reshape(1,3,img_width, img_height)\n",
    "            imgArray = imgArray/float(255)\n",
    "            if int(model.predict_classes(imgArray,verbose=0)) == 1:\n",
    "                cv2.rectangle(img_bgr, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            else:\n",
    "                cv2.rectangle(img_bgr, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "          \n",
    "\n",
    "        count+=1\n",
    "        img_bgr = cv2.resize(img_bgr,(480,680))\n",
    "        cv2.imshow('LATINX', img_bgr)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESNET USING TRANSFER LEARNING BASED ON FACENET WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/rcmalli/keras-vggface.git\n",
      "  Cloning https://github.com/rcmalli/keras-vggface.git to c:\\users\\renato~1.cas\\appdata\\local\\temp\\pip-req-build-fl3e7iy0\n",
      "Requirement already satisfied (use --upgrade to upgrade): keras-vggface==0.5 from git+https://github.com/rcmalli/keras-vggface.git in c:\\users\\renato.castro\\appdata\\local\\continuum\\anaconda3\\envs\\opencvkeras\\lib\\site-packages\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\renato.castro\\appdata\\local\\continuum\\anaconda3\\envs\\opencvkeras\\lib\\site-packages (from keras-vggface==0.5) (1.16.0)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\renato.castro\\appdata\\local\\continuum\\anaconda3\\envs\\opencvkeras\\lib\\site-packages (from keras-vggface==0.5) (1.1.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\renato.castro\\appdata\\local\\continuum\\anaconda3\\envs\\opencvkeras\\lib\\site-packages (from keras-vggface==0.5) (2.8.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\renato.castro\\appdata\\local\\continuum\\anaconda3\\envs\\opencvkeras\\lib\\site-packages (from keras-vggface==0.5) (5.2.0)\n",
      "Requirement already satisfied: keras in c:\\users\\renato.castro\\appdata\\local\\continuum\\anaconda3\\envs\\opencvkeras\\lib\\site-packages (from keras-vggface==0.5) (2.2.4)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\renato.castro\\appdata\\local\\continuum\\anaconda3\\envs\\opencvkeras\\lib\\site-packages (from keras-vggface==0.5) (1.11.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\renato.castro\\appdata\\local\\continuum\\anaconda3\\envs\\opencvkeras\\lib\\site-packages (from keras-vggface==0.5) (3.13)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\renato.castro\\appdata\\local\\continuum\\anaconda3\\envs\\opencvkeras\\lib\\site-packages (from keras->keras-vggface==0.5) (1.0.7)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\renato.castro\\appdata\\local\\continuum\\anaconda3\\envs\\opencvkeras\\lib\\site-packages (from keras->keras-vggface==0.5) (1.0.9)\n",
      "Building wheels for collected packages: keras-vggface\n",
      "  Running setup.py bdist_wheel for keras-vggface: started\n",
      "  Running setup.py bdist_wheel for keras-vggface: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\RENATO~1.CAS\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-k6o1uw90\\wheels\\36\\07\\46\\06c25ce8e9cd396dabe151ea1d8a2bc28dafcb11321c1f3a6d\n",
      "Successfully built keras-vggface\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "twisted 18.7.0 requires PyHamcrest>=1.9.0, which is not installed.\n",
      "tensorflow 1.10.0 has requirement numpy<=1.14.5,>=1.13.3, but you'll have numpy 1.16.0 which is incompatible.\n",
      "tensorflow 1.10.0 has requirement setuptools<=39.1.0, but you'll have setuptools 40.2.0 which is incompatible.\n",
      "You are using pip version 10.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/rcmalli/keras-vggface.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_vggface.vggface import VGGFace\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import callbacks\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_resnet50.h5\n",
      "94699520/94694792 [==============================] - 147s 2us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\renato.castro\\AppData\\Local\\Continuum\\anaconda3\\envs\\opencvkeras\\lib\\site-packages\\keras_vggface\\models.py:298: UserWarning: You are using the TensorFlow backend, yet you are using the Theano image data format convention (`image_data_format=\"channels_first\"`). For best performance, set `image_data_format=\"channels_last\"` in your Keras config at ~/.keras/keras.json.\n",
      "  warnings.warn('You are using the TensorFlow backend, yet you '\n"
     ]
    }
   ],
   "source": [
    "vggface = VGGFace(model='resnet50', input_shape = (3,224,224), pooling = 'avg', include_top = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential \n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from keras.layers import InputLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.pooling.GlobalAveragePooling2D object at 0x0000000023F1A470>\n",
      "175\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in vggface.layers:\n",
    "    count += 1\n",
    "    if(count == 175):\n",
    "        print(i)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Shape:0' shape=(2,) dtype=int32>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.shape(vggface.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 3, 224, 224)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1/7x7_s2 (Conv2D)           (None, 64, 112, 112) 9408        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/7x7_s2/bn (BatchNormaliza (None, 64, 112, 112) 256         conv1/7x7_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 112, 112) 0           conv1/7x7_s2/bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 55, 55)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_reduce (Conv2D)     (None, 64, 55, 55)   4096        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_reduce/bn (BatchNor (None, 64, 55, 55)   256         conv2_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 55, 55)   0           conv2_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_3x3 (Conv2D)            (None, 64, 55, 55)   36864       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_3x3/bn (BatchNormalizat (None, 64, 55, 55)   256         conv2_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 55, 55)   0           conv2_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_increase (Conv2D)   (None, 256, 55, 55)  16384       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_proj (Conv2D)       (None, 256, 55, 55)  16384       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_increase/bn (BatchN (None, 256, 55, 55)  1024        conv2_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_proj/bn (BatchNorma (None, 256, 55, 55)  1024        conv2_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 256, 55, 55)  0           conv2_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv2_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 256, 55, 55)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_reduce (Conv2D)     (None, 64, 55, 55)   16384       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_reduce/bn (BatchNor (None, 64, 55, 55)   256         conv2_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 55, 55)   0           conv2_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_3x3 (Conv2D)            (None, 64, 55, 55)   36864       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_3x3/bn (BatchNormalizat (None, 64, 55, 55)   256         conv2_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 55, 55)   0           conv2_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_increase (Conv2D)   (None, 256, 55, 55)  16384       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_increase/bn (BatchN (None, 256, 55, 55)  1024        conv2_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 256, 55, 55)  0           conv2_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 256, 55, 55)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_reduce (Conv2D)     (None, 64, 55, 55)   16384       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_reduce/bn (BatchNor (None, 64, 55, 55)   256         conv2_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 55, 55)   0           conv2_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_3x3 (Conv2D)            (None, 64, 55, 55)   36864       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_3x3/bn (BatchNormalizat (None, 64, 55, 55)   256         conv2_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 64, 55, 55)   0           conv2_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_increase (Conv2D)   (None, 256, 55, 55)  16384       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_increase/bn (BatchN (None, 256, 55, 55)  1024        conv2_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 256, 55, 55)  0           conv2_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 256, 55, 55)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_reduce (Conv2D)     (None, 128, 28, 28)  32768       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_reduce/bn (BatchNor (None, 128, 28, 28)  512         conv3_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 128, 28, 28)  0           conv3_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_3x3 (Conv2D)            (None, 128, 28, 28)  147456      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_3x3/bn (BatchNormalizat (None, 128, 28, 28)  512         conv3_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 128, 28, 28)  0           conv3_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_increase (Conv2D)   (None, 512, 28, 28)  65536       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_proj (Conv2D)       (None, 512, 28, 28)  131072      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_increase/bn (BatchN (None, 512, 28, 28)  2048        conv3_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_proj/bn (BatchNorma (None, 512, 28, 28)  2048        conv3_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 512, 28, 28)  0           conv3_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv3_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 512, 28, 28)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_reduce (Conv2D)     (None, 128, 28, 28)  65536       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_reduce/bn (BatchNor (None, 128, 28, 28)  512         conv3_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 128, 28, 28)  0           conv3_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_3x3 (Conv2D)            (None, 128, 28, 28)  147456      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_3x3/bn (BatchNormalizat (None, 128, 28, 28)  512         conv3_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 128, 28, 28)  0           conv3_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_increase (Conv2D)   (None, 512, 28, 28)  65536       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_increase/bn (BatchN (None, 512, 28, 28)  2048        conv3_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 512, 28, 28)  0           conv3_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 512, 28, 28)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_reduce (Conv2D)     (None, 128, 28, 28)  65536       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_reduce/bn (BatchNor (None, 128, 28, 28)  512         conv3_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 128, 28, 28)  0           conv3_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_3x3 (Conv2D)            (None, 128, 28, 28)  147456      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_3x3/bn (BatchNormalizat (None, 128, 28, 28)  512         conv3_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 128, 28, 28)  0           conv3_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_increase (Conv2D)   (None, 512, 28, 28)  65536       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_increase/bn (BatchN (None, 512, 28, 28)  2048        conv3_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 512, 28, 28)  0           conv3_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 512, 28, 28)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_reduce (Conv2D)     (None, 128, 28, 28)  65536       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_reduce/bn (BatchNor (None, 128, 28, 28)  512         conv3_4_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 128, 28, 28)  0           conv3_4_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_3x3 (Conv2D)            (None, 128, 28, 28)  147456      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_3x3/bn (BatchNormalizat (None, 128, 28, 28)  512         conv3_4_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 128, 28, 28)  0           conv3_4_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_increase (Conv2D)   (None, 512, 28, 28)  65536       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_increase/bn (BatchN (None, 512, 28, 28)  2048        conv3_4_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 512, 28, 28)  0           conv3_4_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 512, 28, 28)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_reduce (Conv2D)     (None, 256, 14, 14)  131072      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_reduce/bn (BatchNor (None, 256, 14, 14)  1024        conv4_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 256, 14, 14)  0           conv4_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_3x3 (Conv2D)            (None, 256, 14, 14)  589824      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_3x3/bn (BatchNormalizat (None, 256, 14, 14)  1024        conv4_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 256, 14, 14)  0           conv4_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_increase (Conv2D)   (None, 1024, 14, 14) 262144      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_proj (Conv2D)       (None, 1024, 14, 14) 524288      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_increase/bn (BatchN (None, 1024, 14, 14) 4096        conv4_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_proj/bn (BatchNorma (None, 1024, 14, 14) 4096        conv4_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 1024, 14, 14) 0           conv4_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv4_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 1024, 14, 14) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_reduce (Conv2D)     (None, 256, 14, 14)  262144      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_reduce/bn (BatchNor (None, 256, 14, 14)  1024        conv4_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 256, 14, 14)  0           conv4_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_3x3 (Conv2D)            (None, 256, 14, 14)  589824      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_3x3/bn (BatchNormalizat (None, 256, 14, 14)  1024        conv4_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 256, 14, 14)  0           conv4_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_increase (Conv2D)   (None, 1024, 14, 14) 262144      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_increase/bn (BatchN (None, 1024, 14, 14) 4096        conv4_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 1024, 14, 14) 0           conv4_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 1024, 14, 14) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_reduce (Conv2D)     (None, 256, 14, 14)  262144      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_reduce/bn (BatchNor (None, 256, 14, 14)  1024        conv4_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 256, 14, 14)  0           conv4_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_3x3 (Conv2D)            (None, 256, 14, 14)  589824      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_3x3/bn (BatchNormalizat (None, 256, 14, 14)  1024        conv4_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 256, 14, 14)  0           conv4_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_increase (Conv2D)   (None, 1024, 14, 14) 262144      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_increase/bn (BatchN (None, 1024, 14, 14) 4096        conv4_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 1024, 14, 14) 0           conv4_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 1024, 14, 14) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_reduce (Conv2D)     (None, 256, 14, 14)  262144      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_reduce/bn (BatchNor (None, 256, 14, 14)  1024        conv4_4_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 256, 14, 14)  0           conv4_4_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_3x3 (Conv2D)            (None, 256, 14, 14)  589824      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_3x3/bn (BatchNormalizat (None, 256, 14, 14)  1024        conv4_4_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 256, 14, 14)  0           conv4_4_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_increase (Conv2D)   (None, 1024, 14, 14) 262144      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_increase/bn (BatchN (None, 1024, 14, 14) 4096        conv4_4_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 1024, 14, 14) 0           conv4_4_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 1024, 14, 14) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_reduce (Conv2D)     (None, 256, 14, 14)  262144      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_reduce/bn (BatchNor (None, 256, 14, 14)  1024        conv4_5_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 256, 14, 14)  0           conv4_5_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_3x3 (Conv2D)            (None, 256, 14, 14)  589824      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_3x3/bn (BatchNormalizat (None, 256, 14, 14)  1024        conv4_5_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 256, 14, 14)  0           conv4_5_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_increase (Conv2D)   (None, 1024, 14, 14) 262144      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_increase/bn (BatchN (None, 1024, 14, 14) 4096        conv4_5_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 1024, 14, 14) 0           conv4_5_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 1024, 14, 14) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_reduce (Conv2D)     (None, 256, 14, 14)  262144      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_reduce/bn (BatchNor (None, 256, 14, 14)  1024        conv4_6_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 256, 14, 14)  0           conv4_6_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_3x3 (Conv2D)            (None, 256, 14, 14)  589824      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_3x3/bn (BatchNormalizat (None, 256, 14, 14)  1024        conv4_6_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 256, 14, 14)  0           conv4_6_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_increase (Conv2D)   (None, 1024, 14, 14) 262144      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_increase/bn (BatchN (None, 1024, 14, 14) 4096        conv4_6_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 1024, 14, 14) 0           conv4_6_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 1024, 14, 14) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_reduce (Conv2D)     (None, 512, 7, 7)    524288      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_reduce/bn (BatchNor (None, 512, 7, 7)    2048        conv5_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 512, 7, 7)    0           conv5_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_3x3 (Conv2D)            (None, 512, 7, 7)    2359296     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_3x3/bn (BatchNormalizat (None, 512, 7, 7)    2048        conv5_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 512, 7, 7)    0           conv5_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_increase (Conv2D)   (None, 2048, 7, 7)   1048576     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_proj (Conv2D)       (None, 2048, 7, 7)   2097152     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_increase/bn (BatchN (None, 2048, 7, 7)   8192        conv5_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_proj/bn (BatchNorma (None, 2048, 7, 7)   8192        conv5_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 2048, 7, 7)   0           conv5_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv5_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 2048, 7, 7)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_reduce (Conv2D)     (None, 512, 7, 7)    1048576     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_reduce/bn (BatchNor (None, 512, 7, 7)    2048        conv5_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 512, 7, 7)    0           conv5_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_3x3 (Conv2D)            (None, 512, 7, 7)    2359296     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_3x3/bn (BatchNormalizat (None, 512, 7, 7)    2048        conv5_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 512, 7, 7)    0           conv5_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_increase (Conv2D)   (None, 2048, 7, 7)   1048576     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_increase/bn (BatchN (None, 2048, 7, 7)   8192        conv5_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 2048, 7, 7)   0           conv5_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 2048, 7, 7)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_reduce (Conv2D)     (None, 512, 7, 7)    1048576     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_reduce/bn (BatchNor (None, 512, 7, 7)    2048        conv5_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 512, 7, 7)    0           conv5_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_3x3 (Conv2D)            (None, 512, 7, 7)    2359296     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_3x3/bn (BatchNormalizat (None, 512, 7, 7)    2048        conv5_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 512, 7, 7)    0           conv5_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_increase (Conv2D)   (None, 2048, 7, 7)   1048576     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_increase/bn (BatchN (None, 2048, 7, 7)   8192        conv5_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 2048, 7, 7)   0           conv5_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 2048, 7, 7)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 2048, 1, 1)   0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,561,152\n",
      "Trainable params: 23,508,032\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vggface.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 3, 224, 224)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1/7x7_s2 (Conv2D)           (None, 64, 112, 112) 9408        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/7x7_s2/bn (BatchNormaliza (None, 64, 112, 112) 256         conv1/7x7_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 112, 112) 0           conv1/7x7_s2/bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 55, 55)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_reduce (Conv2D)     (None, 64, 55, 55)   4096        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_reduce/bn (BatchNor (None, 64, 55, 55)   256         conv2_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 55, 55)   0           conv2_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_3x3 (Conv2D)            (None, 64, 55, 55)   36864       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_3x3/bn (BatchNormalizat (None, 64, 55, 55)   256         conv2_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 55, 55)   0           conv2_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_increase (Conv2D)   (None, 256, 55, 55)  16384       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_proj (Conv2D)       (None, 256, 55, 55)  16384       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_increase/bn (BatchN (None, 256, 55, 55)  1024        conv2_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_proj/bn (BatchNorma (None, 256, 55, 55)  1024        conv2_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 256, 55, 55)  0           conv2_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv2_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 256, 55, 55)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_reduce (Conv2D)     (None, 64, 55, 55)   16384       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_reduce/bn (BatchNor (None, 64, 55, 55)   256         conv2_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 55, 55)   0           conv2_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_3x3 (Conv2D)            (None, 64, 55, 55)   36864       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_3x3/bn (BatchNormalizat (None, 64, 55, 55)   256         conv2_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 55, 55)   0           conv2_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_increase (Conv2D)   (None, 256, 55, 55)  16384       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_increase/bn (BatchN (None, 256, 55, 55)  1024        conv2_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 256, 55, 55)  0           conv2_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 256, 55, 55)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_reduce (Conv2D)     (None, 64, 55, 55)   16384       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_reduce/bn (BatchNor (None, 64, 55, 55)   256         conv2_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 55, 55)   0           conv2_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_3x3 (Conv2D)            (None, 64, 55, 55)   36864       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_3x3/bn (BatchNormalizat (None, 64, 55, 55)   256         conv2_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 64, 55, 55)   0           conv2_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_increase (Conv2D)   (None, 256, 55, 55)  16384       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_increase/bn (BatchN (None, 256, 55, 55)  1024        conv2_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 256, 55, 55)  0           conv2_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 256, 55, 55)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_reduce (Conv2D)     (None, 128, 28, 28)  32768       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_reduce/bn (BatchNor (None, 128, 28, 28)  512         conv3_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 128, 28, 28)  0           conv3_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_3x3 (Conv2D)            (None, 128, 28, 28)  147456      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_3x3/bn (BatchNormalizat (None, 128, 28, 28)  512         conv3_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 128, 28, 28)  0           conv3_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_increase (Conv2D)   (None, 512, 28, 28)  65536       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_proj (Conv2D)       (None, 512, 28, 28)  131072      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_increase/bn (BatchN (None, 512, 28, 28)  2048        conv3_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_proj/bn (BatchNorma (None, 512, 28, 28)  2048        conv3_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 512, 28, 28)  0           conv3_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv3_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 512, 28, 28)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_reduce (Conv2D)     (None, 128, 28, 28)  65536       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_reduce/bn (BatchNor (None, 128, 28, 28)  512         conv3_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 128, 28, 28)  0           conv3_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_3x3 (Conv2D)            (None, 128, 28, 28)  147456      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_3x3/bn (BatchNormalizat (None, 128, 28, 28)  512         conv3_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 128, 28, 28)  0           conv3_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_increase (Conv2D)   (None, 512, 28, 28)  65536       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_increase/bn (BatchN (None, 512, 28, 28)  2048        conv3_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 512, 28, 28)  0           conv3_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 512, 28, 28)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_reduce (Conv2D)     (None, 128, 28, 28)  65536       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_reduce/bn (BatchNor (None, 128, 28, 28)  512         conv3_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 128, 28, 28)  0           conv3_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_3x3 (Conv2D)            (None, 128, 28, 28)  147456      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_3x3/bn (BatchNormalizat (None, 128, 28, 28)  512         conv3_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 128, 28, 28)  0           conv3_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_increase (Conv2D)   (None, 512, 28, 28)  65536       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_increase/bn (BatchN (None, 512, 28, 28)  2048        conv3_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 512, 28, 28)  0           conv3_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 512, 28, 28)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_reduce (Conv2D)     (None, 128, 28, 28)  65536       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_reduce/bn (BatchNor (None, 128, 28, 28)  512         conv3_4_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 128, 28, 28)  0           conv3_4_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_3x3 (Conv2D)            (None, 128, 28, 28)  147456      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_3x3/bn (BatchNormalizat (None, 128, 28, 28)  512         conv3_4_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 128, 28, 28)  0           conv3_4_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_increase (Conv2D)   (None, 512, 28, 28)  65536       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_increase/bn (BatchN (None, 512, 28, 28)  2048        conv3_4_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 512, 28, 28)  0           conv3_4_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 512, 28, 28)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_reduce (Conv2D)     (None, 256, 14, 14)  131072      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_reduce/bn (BatchNor (None, 256, 14, 14)  1024        conv4_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 256, 14, 14)  0           conv4_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_3x3 (Conv2D)            (None, 256, 14, 14)  589824      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_3x3/bn (BatchNormalizat (None, 256, 14, 14)  1024        conv4_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 256, 14, 14)  0           conv4_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_increase (Conv2D)   (None, 1024, 14, 14) 262144      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_proj (Conv2D)       (None, 1024, 14, 14) 524288      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_increase/bn (BatchN (None, 1024, 14, 14) 4096        conv4_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_proj/bn (BatchNorma (None, 1024, 14, 14) 4096        conv4_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 1024, 14, 14) 0           conv4_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv4_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 1024, 14, 14) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_reduce (Conv2D)     (None, 256, 14, 14)  262144      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_reduce/bn (BatchNor (None, 256, 14, 14)  1024        conv4_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 256, 14, 14)  0           conv4_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_3x3 (Conv2D)            (None, 256, 14, 14)  589824      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_3x3/bn (BatchNormalizat (None, 256, 14, 14)  1024        conv4_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 256, 14, 14)  0           conv4_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_increase (Conv2D)   (None, 1024, 14, 14) 262144      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_increase/bn (BatchN (None, 1024, 14, 14) 4096        conv4_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 1024, 14, 14) 0           conv4_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 1024, 14, 14) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_reduce (Conv2D)     (None, 256, 14, 14)  262144      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_reduce/bn (BatchNor (None, 256, 14, 14)  1024        conv4_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 256, 14, 14)  0           conv4_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_3x3 (Conv2D)            (None, 256, 14, 14)  589824      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_3x3/bn (BatchNormalizat (None, 256, 14, 14)  1024        conv4_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 256, 14, 14)  0           conv4_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_increase (Conv2D)   (None, 1024, 14, 14) 262144      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_increase/bn (BatchN (None, 1024, 14, 14) 4096        conv4_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 1024, 14, 14) 0           conv4_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 1024, 14, 14) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_reduce (Conv2D)     (None, 256, 14, 14)  262144      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_reduce/bn (BatchNor (None, 256, 14, 14)  1024        conv4_4_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 256, 14, 14)  0           conv4_4_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_3x3 (Conv2D)            (None, 256, 14, 14)  589824      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_3x3/bn (BatchNormalizat (None, 256, 14, 14)  1024        conv4_4_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 256, 14, 14)  0           conv4_4_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_increase (Conv2D)   (None, 1024, 14, 14) 262144      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_increase/bn (BatchN (None, 1024, 14, 14) 4096        conv4_4_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 1024, 14, 14) 0           conv4_4_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 1024, 14, 14) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_reduce (Conv2D)     (None, 256, 14, 14)  262144      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_reduce/bn (BatchNor (None, 256, 14, 14)  1024        conv4_5_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 256, 14, 14)  0           conv4_5_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_3x3 (Conv2D)            (None, 256, 14, 14)  589824      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_3x3/bn (BatchNormalizat (None, 256, 14, 14)  1024        conv4_5_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 256, 14, 14)  0           conv4_5_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_increase (Conv2D)   (None, 1024, 14, 14) 262144      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_increase/bn (BatchN (None, 1024, 14, 14) 4096        conv4_5_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 1024, 14, 14) 0           conv4_5_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 1024, 14, 14) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_reduce (Conv2D)     (None, 256, 14, 14)  262144      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_reduce/bn (BatchNor (None, 256, 14, 14)  1024        conv4_6_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 256, 14, 14)  0           conv4_6_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_3x3 (Conv2D)            (None, 256, 14, 14)  589824      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_3x3/bn (BatchNormalizat (None, 256, 14, 14)  1024        conv4_6_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 256, 14, 14)  0           conv4_6_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_increase (Conv2D)   (None, 1024, 14, 14) 262144      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_increase/bn (BatchN (None, 1024, 14, 14) 4096        conv4_6_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 1024, 14, 14) 0           conv4_6_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 1024, 14, 14) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_reduce (Conv2D)     (None, 512, 7, 7)    524288      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_reduce/bn (BatchNor (None, 512, 7, 7)    2048        conv5_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 512, 7, 7)    0           conv5_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_3x3 (Conv2D)            (None, 512, 7, 7)    2359296     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_3x3/bn (BatchNormalizat (None, 512, 7, 7)    2048        conv5_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 512, 7, 7)    0           conv5_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_increase (Conv2D)   (None, 2048, 7, 7)   1048576     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_proj (Conv2D)       (None, 2048, 7, 7)   2097152     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_increase/bn (BatchN (None, 2048, 7, 7)   8192        conv5_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_proj/bn (BatchNorma (None, 2048, 7, 7)   8192        conv5_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 2048, 7, 7)   0           conv5_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv5_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 2048, 7, 7)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_reduce (Conv2D)     (None, 512, 7, 7)    1048576     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_reduce/bn (BatchNor (None, 512, 7, 7)    2048        conv5_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 512, 7, 7)    0           conv5_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_3x3 (Conv2D)            (None, 512, 7, 7)    2359296     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_3x3/bn (BatchNormalizat (None, 512, 7, 7)    2048        conv5_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 512, 7, 7)    0           conv5_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_increase (Conv2D)   (None, 2048, 7, 7)   1048576     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_increase/bn (BatchN (None, 2048, 7, 7)   8192        conv5_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 2048, 7, 7)   0           conv5_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 2048, 7, 7)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_reduce (Conv2D)     (None, 512, 7, 7)    1048576     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_reduce/bn (BatchNor (None, 512, 7, 7)    2048        conv5_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 512, 7, 7)    0           conv5_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_3x3 (Conv2D)            (None, 512, 7, 7)    2359296     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_3x3/bn (BatchNormalizat (None, 512, 7, 7)    2048        conv5_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 512, 7, 7)    0           conv5_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_increase (Conv2D)   (None, 2048, 7, 7)   1048576     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_increase/bn (BatchN (None, 2048, 7, 7)   8192        conv5_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 2048, 7, 7)   0           conv5_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 2048, 7, 7)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 2048, 1, 1)   0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "classifier (Dense)              (None, 1)            2049        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,563,201\n",
      "Trainable params: 2,049\n",
      "Non-trainable params: 23,561,152\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.engine import  Model\n",
    "from keras.layers import Flatten, Dense, Input, InputLayer\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "#import pandas as pd\n",
    "#custom parameters\n",
    "nb_class = 2\n",
    "hidden_dim = 256\n",
    "\n",
    "#vgg_model = VGGFace(include_top=False, input_shape=(224, 224, 3))\n",
    "#last_layer = Input(vggface.output)\n",
    "#print(last_layer)\n",
    "#your_input = Input(shape=output_shape_of_resnet)\n",
    "#x = Flatten(your_input)\n",
    "#input_shape = vggface.output_shape[1]\n",
    "\n",
    "last_layer = vggface.get_layer('avg_pool').output\n",
    "x = Flatten(name='flatten')(last_layer)\n",
    "out = Dense(1, activation='sigmoid', name='classifier')(x)\n",
    "#vggface.trainable = False\n",
    "\n",
    "model = Model(vggface.input, out)\n",
    "count = 0\n",
    "for layer in model.layers:\n",
    "    if(count<= 173):\n",
    "        layer.trainable = False\n",
    "        count += 1\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "model.output.trainable = True\n",
    "\n",
    "\n",
    "layers = [(layer, layer.name, layer.trainable) for layer in model.layers]\n",
    "#r = pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])  \n",
    "\n",
    "#model = Model(vggface.input, out)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "           optimizer=Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-6),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "#from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.resnet50 import preprocess_input \n",
    "from keras.applications.resnet50 import decode_predictions\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip = True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = data_generator.flow_from_directory(\n",
    "            r'../Train',\n",
    "            target_size = (224,224),\n",
    "            batch_size = 100,\n",
    "            class_mode = 'binary')\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "            r'../Validation',\n",
    "            target_size = (224,224),\n",
    "            batch_size = 100,\n",
    "            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filepath='weights/latinxinai_resnet_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: <keras.layers.pooling.GlobalAveragePooling2D object at 0x0000000023F1A470>\n",
      "Predicted: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "img = image.load_img('fake1_test.jpg',target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x) # or version=2\n",
    "preds = model.predict(x)\n",
    "print('Correct:', i )\n",
    "print('Predicted:', np.argmax(preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras_vggface import utils\n",
    "if __name__ == \"__main__\":\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    img_width = 96\n",
    "    img_height = 96\n",
    "    \n",
    "    cascPath = \"haarcascade_frontalface_default.xml\"\n",
    "    faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "\n",
    "    sample_number = 1\n",
    "    count = 0\n",
    "    measures = np.zeros(sample_number, dtype=np.float)\n",
    "\n",
    "    while True:\n",
    "        ret, img_bgr = cap.read()\n",
    "        if ret is False:\n",
    "            print(\"Camera not found. Turn it on\")\n",
    "            break\n",
    "\n",
    "        img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        faces = faceCascade.detectMultiScale(img_gray, scaleFactor = 1.05, minNeighbors = 5) \n",
    "\n",
    "        frame = cv2.resize(img_bgr,(224,224))\n",
    "        for i, (x, y, w, h) in enumerate(faces):\n",
    "            imgArray = frame.reshape(1,3,224, 224)\n",
    "            imgArray = imgArray/float(255)\n",
    "            preds = int(model.predict(imgArray,verbose = 0))\n",
    "            if np.argmax(preds) == 1:\n",
    "                cv2.rectangle(img_bgr, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            else:\n",
    "                cv2.rectangle(img_bgr, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "            \n",
    "        count+=1\n",
    "        img_bgr = cv2.resize(img_bgr,(480,680))\n",
    "        cv2.imshow('LATINX', img_bgr)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
